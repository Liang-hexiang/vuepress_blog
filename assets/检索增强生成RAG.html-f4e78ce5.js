const a=JSON.parse('{"key":"v-706654d0","path":"/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90RAG.html","title":"RAG 简介","lang":"zh-CN","frontmatter":{"icon":"fas fa-database","date":"2025-01-03T00:00:00.000Z","cover":"https://img.tucang.cc/api/image/show/6c8acb93bd0fc9dd85006746d572df8f","category":["人工智能"],"tag":["RAG","LLM"]},"headers":[{"level":2,"title":"[一、什么是 RAG](https://datawhalechina.github.io/llm-universe/#/C1/2.检索增强生成 RAG 简介?id=一、什么是-rag)","slug":"一、什么是-rag-https-datawhalechina-github-io-llm-universe-c1-2-检索增强生成-rag-简介-id-一、什么是-rag","link":"#一、什么是-rag-https-datawhalechina-github-io-llm-universe-c1-2-检索增强生成-rag-简介-id-一、什么是-rag","children":[]},{"level":2,"title":"[二、RAG 的工作流程](https://datawhalechina.github.io/llm-universe/#/C1/2.检索增强生成 RAG 简介?id=二、rag-的工作流程)","slug":"二、rag-的工作流程-https-datawhalechina-github-io-llm-universe-c1-2-检索增强生成-rag-简介-id-二、rag-的工作流程","link":"#二、rag-的工作流程-https-datawhalechina-github-io-llm-universe-c1-2-检索增强生成-rag-简介-id-二、rag-的工作流程","children":[]},{"level":2,"title":"[三、RAG VS Finetune](https://datawhalechina.github.io/llm-universe/#/C1/2.检索增强生成 RAG 简介?id=三、rag-vs-finetune)","slug":"三、rag-vs-finetune-https-datawhalechina-github-io-llm-universe-c1-2-检索增强生成-rag-简介-id-三、rag-vs-finetune","link":"#三、rag-vs-finetune-https-datawhalechina-github-io-llm-universe-c1-2-检索增强生成-rag-简介-id-三、rag-vs-finetune","children":[]},{"level":2,"title":"[四、RAG 的成功案例](https://datawhalechina.github.io/llm-universe/#/C1/2.检索增强生成 RAG 简介?id=四、rag-的成功案例)","slug":"四、rag-的成功案例-https-datawhalechina-github-io-llm-universe-c1-2-检索增强生成-rag-简介-id-四、rag-的成功案例","link":"#四、rag-的成功案例-https-datawhalechina-github-io-llm-universe-c1-2-检索增强生成-rag-简介-id-四、rag-的成功案例","children":[]}],"git":{"createdTime":1739233761000,"updatedTime":1739233761000,"contributors":[{"name":"lianghexiang","email":"lhx110396@163.com","commits":1}]},"readingTime":{"minutes":6.65,"words":1995},"filePathRelative":"人工智能/LLM/检索增强生成RAG.md","localizedDate":"2025年1月3日","excerpt":"<h1> RAG 简介</h1>\\n<h2> [一、什么是 RAG](<a href=\\"https://datawhalechina.github.io/llm-universe/#/C1/2.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://datawhalechina.github.io/llm-universe/#/C1/2.检索增强生成</a> RAG 简介?id=一、什么是-rag)</h2>\\n<p>大型语言模型（LLM）相较于传统的语言模型具有更强大的能力，然而在某些情况下，它们仍可能无法提供准确的答案。为了解决大型语言模型在生成文本时面临的一系列挑战，提高模型的性能和输出质量，研究人员提出了一种新的模型架构：<strong>检索增强生成（RAG, Retrieval-Augmented Generation）</strong>。该架构巧妙地<strong>整合了从庞大知识库中检索到的相关信息，并以此为基础，指导大型语言模型生成更为精准的答案</strong>，从而显著提升了回答的准确性与深度。</p>"}');export{a as data};
