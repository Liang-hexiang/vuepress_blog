<!DOCTYPE html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-beta.63" />
    <meta name="theme" content="VuePress Theme Hope" />
    <link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Ma+Shan+Zheng&display=swap" rel="stylesheet"><link href="https://fonts.googleapis.com/css2?family=Ma+Shan+Zheng&family=ZCOOL+KuaiLe&display=swap" rel="stylesheet"><link rel="manifest" href="/manifest.webmanifest"><script src="https://fastly.jsdelivr.net/gh/stevenjoezhang/live2d-widget@latest/autoload.js"></script><meta name="theme-color" content="#3eaf7c"><link rel="icon" href="/space/favicon.ico"><link rel="icon" href="/space/assets/icon/chrome-mask-512.png" type="image/png" sizes="512x512"><link rel="icon" href="/space/assets/icon/chrome-mask-192.png" type="image/png" sizes="192x192"><link rel="icon" href="/space/assets/icon/chrome-512.png" type="image/png" sizes="512x512"><link rel="icon" href="/space/assets/icon/chrome-192.png" type="image/png" sizes="192x192"><link rel="apple-touch-icon" href="/space/assets/icon/apple-icon-152.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="msapplication-TileImage" content="/space/assets/icon/ms-icon-144.png"><meta name="msapplication-TileColor" content="#ffffff"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover"><title>大语言模型简介 | #/ cd L.H.X Blog Home</title><meta name="description" content="">
    <style>
      :root {
        --bg-color: #fff;
      }

      html[data-theme="dark"] {
        --bg-color: #1d1e1f;
      }

      html,
      body {
        background: var(--bg-color);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <link rel="preload" href="/space/assets/style-3875db4e.css" as="style"><link rel="stylesheet" href="/space/assets/style-3875db4e.css">
    <link rel="modulepreload" href="/space/assets/app-8962bb0b.js"><link rel="modulepreload" href="/space/assets/大语言模型简介.html-67d6b65e.js"><link rel="modulepreload" href="/space/assets/大语言模型简介.html-6518970b.js"><link rel="prefetch" href="/space/assets/index.html-7a607f99.js" as="script"><link rel="prefetch" href="/space/assets/intro.html-4b04e654.js" as="script"><link rel="prefetch" href="/space/assets/slides.html-7ff1e8a5.js" as="script"><link rel="prefetch" href="/space/assets/一切问题的起源.html-ef34264e.js" as="script"><link rel="prefetch" href="/space/assets/下雪啦.html-830caad9.js" as="script"><link rel="prefetch" href="/space/assets/好用网站收藏.html-396fe024.js" as="script"><link rel="prefetch" href="/space/assets/Linux配置环境变量.html-6b579323.js" as="script"><link rel="prefetch" href="/space/assets/Vue基础.html-b7df9071.js" as="script"><link rel="prefetch" href="/space/assets/vue客户端.html-e2594118.js" as="script"><link rel="prefetch" href="/space/assets/单例模式.html-249f9faa.js" as="script"><link rel="prefetch" href="/space/assets/工厂模式.html-609b6146.js" as="script"><link rel="prefetch" href="/space/assets/门面模式.html-a37d4e76.js" as="script"><link rel="prefetch" href="/space/assets/gRPC服务.html-a0674f3a.js" as="script"><link rel="prefetch" href="/space/assets/mysql备忘录.html-ba2c79ab.js" as="script"><link rel="prefetch" href="/space/assets/PySpark之Parallelize.html-aa767ccb.js" as="script"><link rel="prefetch" href="/space/assets/PySpark初学者教程.html-b87d0597.js" as="script"><link rel="prefetch" href="/space/assets/SparkSession教程.html-a8c70834.js" as="script"><link rel="prefetch" href="/space/assets/spark快速大数据分析之Spark数据分析导论.html-5249ddab.js" as="script"><link rel="prefetch" href="/space/assets/DBUtils导入.html-cc5afbe6.js" as="script"><link rel="prefetch" href="/space/assets/PicgoGitHub搭建图床.html-daa855fa.js" as="script"><link rel="prefetch" href="/space/assets/llm-prompt提示原则.html-593e2cf4.js" as="script"><link rel="prefetch" href="/space/assets/向量数据库.html-cc6efaa0.js" as="script"><link rel="prefetch" href="/space/assets/检索增强生成RAG.html-f4e78ce5.js" as="script"><link rel="prefetch" href="/space/assets/404.html-f04ced3e.js" as="script"><link rel="prefetch" href="/space/assets/index.html-601f02ee.js" as="script"><link rel="prefetch" href="/space/assets/index.html-854c2b9a.js" as="script"><link rel="prefetch" href="/space/assets/index.html-fbb0eeec.js" as="script"><link rel="prefetch" href="/space/assets/index.html-cef04db4.js" as="script"><link rel="prefetch" href="/space/assets/index.html-882cd544.js" as="script"><link rel="prefetch" href="/space/assets/index.html-533dd762.js" as="script"><link rel="prefetch" href="/space/assets/index.html-11b84448.js" as="script"><link rel="prefetch" href="/space/assets/index.html-5b76e204.js" as="script"><link rel="prefetch" href="/space/assets/index.html-197d446d.js" as="script"><link rel="prefetch" href="/space/assets/index.html-e77276a5.js" as="script"><link rel="prefetch" href="/space/assets/index.html-c39d8208.js" as="script"><link rel="prefetch" href="/space/assets/index.html-193ba79e.js" as="script"><link rel="prefetch" href="/space/assets/index.html-48f2b30f.js" as="script"><link rel="prefetch" href="/space/assets/index.html-0a80d2ce.js" as="script"><link rel="prefetch" href="/space/assets/index.html-75f6cea3.js" as="script"><link rel="prefetch" href="/space/assets/index.html-88930a72.js" as="script"><link rel="prefetch" href="/space/assets/index.html-19de02d9.js" as="script"><link rel="prefetch" href="/space/assets/index.html-2e547c56.js" as="script"><link rel="prefetch" href="/space/assets/index.html-71fc6e23.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b8bdf50b.js" as="script"><link rel="prefetch" href="/space/assets/index.html-2c24c756.js" as="script"><link rel="prefetch" href="/space/assets/index.html-56c93f1b.js" as="script"><link rel="prefetch" href="/space/assets/index.html-ec07a855.js" as="script"><link rel="prefetch" href="/space/assets/index.html-f6d7ba4f.js" as="script"><link rel="prefetch" href="/space/assets/index.html-17fa5317.js" as="script"><link rel="prefetch" href="/space/assets/index.html-0d7726b0.js" as="script"><link rel="prefetch" href="/space/assets/index.html-e56fcd40.js" as="script"><link rel="prefetch" href="/space/assets/index.html-9fb4f041.js" as="script"><link rel="prefetch" href="/space/assets/index.html-7d3b71cf.js" as="script"><link rel="prefetch" href="/space/assets/index.html-d4a9efb7.js" as="script"><link rel="prefetch" href="/space/assets/index.html-c1a80df9.js" as="script"><link rel="prefetch" href="/space/assets/index.html-ec0bd9a8.js" as="script"><link rel="prefetch" href="/space/assets/index.html-34d92cbe.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b6819a02.js" as="script"><link rel="prefetch" href="/space/assets/index.html-31c79447.js" as="script"><link rel="prefetch" href="/space/assets/index.html-c0c5c54f.js" as="script"><link rel="prefetch" href="/space/assets/index.html-8895d62c.js" as="script"><link rel="prefetch" href="/space/assets/index.html-125a6875.js" as="script"><link rel="prefetch" href="/space/assets/index.html-f3854866.js" as="script"><link rel="prefetch" href="/space/assets/index.html-fafcfe5c.js" as="script"><link rel="prefetch" href="/space/assets/index.html-496c575b.js" as="script"><link rel="prefetch" href="/space/assets/index.html-8cdc0dff.js" as="script"><link rel="prefetch" href="/space/assets/index.html-5794da28.js" as="script"><link rel="prefetch" href="/space/assets/index.html-4a4477e4.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b8610475.js" as="script"><link rel="prefetch" href="/space/assets/index.html-a25b0ef9.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b61462d1.js" as="script"><link rel="prefetch" href="/space/assets/index.html-7e694ee9.js" as="script"><link rel="prefetch" href="/space/assets/index.html-7363c68f.js" as="script"><link rel="prefetch" href="/space/assets/index.html-15044307.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b689fc4a.js" as="script"><link rel="prefetch" href="/space/assets/index.html-bf153e85.js" as="script"><link rel="prefetch" href="/space/assets/index.html-2a3bf5aa.js" as="script"><link rel="prefetch" href="/space/assets/intro.html-f66223bc.js" as="script"><link rel="prefetch" href="/space/assets/slides.html-56fceb82.js" as="script"><link rel="prefetch" href="/space/assets/一切问题的起源.html-17d90afe.js" as="script"><link rel="prefetch" href="/space/assets/下雪啦.html-134c3164.js" as="script"><link rel="prefetch" href="/space/assets/好用网站收藏.html-a5863ff3.js" as="script"><link rel="prefetch" href="/space/assets/Linux配置环境变量.html-f4d3903f.js" as="script"><link rel="prefetch" href="/space/assets/Vue基础.html-9ab92a8c.js" as="script"><link rel="prefetch" href="/space/assets/vue客户端.html-ec8dee44.js" as="script"><link rel="prefetch" href="/space/assets/单例模式.html-dc726d87.js" as="script"><link rel="prefetch" href="/space/assets/工厂模式.html-305e9fe5.js" as="script"><link rel="prefetch" href="/space/assets/门面模式.html-fca15bfa.js" as="script"><link rel="prefetch" href="/space/assets/gRPC服务.html-e7713b1f.js" as="script"><link rel="prefetch" href="/space/assets/mysql备忘录.html-350e3984.js" as="script"><link rel="prefetch" href="/space/assets/PySpark之Parallelize.html-ceeb61b0.js" as="script"><link rel="prefetch" href="/space/assets/PySpark初学者教程.html-98189b3b.js" as="script"><link rel="prefetch" href="/space/assets/SparkSession教程.html-eec9e542.js" as="script"><link rel="prefetch" href="/space/assets/spark快速大数据分析之Spark数据分析导论.html-97b70795.js" as="script"><link rel="prefetch" href="/space/assets/DBUtils导入.html-18290e94.js" as="script"><link rel="prefetch" href="/space/assets/PicgoGitHub搭建图床.html-17075a5e.js" as="script"><link rel="prefetch" href="/space/assets/llm-prompt提示原则.html-71baeaf8.js" as="script"><link rel="prefetch" href="/space/assets/向量数据库.html-e71948e1.js" as="script"><link rel="prefetch" href="/space/assets/检索增强生成RAG.html-30625bee.js" as="script"><link rel="prefetch" href="/space/assets/404.html-0dc4f521.js" as="script"><link rel="prefetch" href="/space/assets/index.html-270c3db8.js" as="script"><link rel="prefetch" href="/space/assets/index.html-8f65b2ac.js" as="script"><link rel="prefetch" href="/space/assets/index.html-7680f14a.js" as="script"><link rel="prefetch" href="/space/assets/index.html-ff6f2f42.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b87aaaa9.js" as="script"><link rel="prefetch" href="/space/assets/index.html-3dd06aaa.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b809b8a0.js" as="script"><link rel="prefetch" href="/space/assets/index.html-acd15a3f.js" as="script"><link rel="prefetch" href="/space/assets/index.html-0b6ac9d0.js" as="script"><link rel="prefetch" href="/space/assets/index.html-9c4c0d02.js" as="script"><link rel="prefetch" href="/space/assets/index.html-845375e3.js" as="script"><link rel="prefetch" href="/space/assets/index.html-1301a959.js" as="script"><link rel="prefetch" href="/space/assets/index.html-a1b1ee7f.js" as="script"><link rel="prefetch" href="/space/assets/index.html-cdf49143.js" as="script"><link rel="prefetch" href="/space/assets/index.html-2e7c2586.js" as="script"><link rel="prefetch" href="/space/assets/index.html-07eb08e5.js" as="script"><link rel="prefetch" href="/space/assets/index.html-90d6f12f.js" as="script"><link rel="prefetch" href="/space/assets/index.html-96ed3fdc.js" as="script"><link rel="prefetch" href="/space/assets/index.html-6232c02a.js" as="script"><link rel="prefetch" href="/space/assets/index.html-6f4756d8.js" as="script"><link rel="prefetch" href="/space/assets/index.html-2b636962.js" as="script"><link rel="prefetch" href="/space/assets/index.html-e374e98e.js" as="script"><link rel="prefetch" href="/space/assets/index.html-66893ca7.js" as="script"><link rel="prefetch" href="/space/assets/index.html-32f5aed8.js" as="script"><link rel="prefetch" href="/space/assets/index.html-01f3fb5a.js" as="script"><link rel="prefetch" href="/space/assets/index.html-375eb3aa.js" as="script"><link rel="prefetch" href="/space/assets/index.html-7f86791d.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b488961b.js" as="script"><link rel="prefetch" href="/space/assets/index.html-63fac6d8.js" as="script"><link rel="prefetch" href="/space/assets/index.html-1541c3fd.js" as="script"><link rel="prefetch" href="/space/assets/index.html-a130f035.js" as="script"><link rel="prefetch" href="/space/assets/index.html-9669f355.js" as="script"><link rel="prefetch" href="/space/assets/index.html-08bce3bc.js" as="script"><link rel="prefetch" href="/space/assets/index.html-f83d226f.js" as="script"><link rel="prefetch" href="/space/assets/index.html-ea8e0886.js" as="script"><link rel="prefetch" href="/space/assets/index.html-60ef43a5.js" as="script"><link rel="prefetch" href="/space/assets/index.html-e9bb5751.js" as="script"><link rel="prefetch" href="/space/assets/index.html-a8fdced9.js" as="script"><link rel="prefetch" href="/space/assets/index.html-a1d3fae6.js" as="script"><link rel="prefetch" href="/space/assets/index.html-3a4cc8f1.js" as="script"><link rel="prefetch" href="/space/assets/index.html-500af1dc.js" as="script"><link rel="prefetch" href="/space/assets/index.html-1f821a64.js" as="script"><link rel="prefetch" href="/space/assets/index.html-4916d936.js" as="script"><link rel="prefetch" href="/space/assets/index.html-51b1fc72.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b30d2ca9.js" as="script"><link rel="prefetch" href="/space/assets/index.html-1ecdbca3.js" as="script"><link rel="prefetch" href="/space/assets/index.html-2583e395.js" as="script"><link rel="prefetch" href="/space/assets/index.html-3cdd1d91.js" as="script"><link rel="prefetch" href="/space/assets/index.html-9552c1b3.js" as="script"><link rel="prefetch" href="/space/assets/index.html-bf351882.js" as="script"><link rel="prefetch" href="/space/assets/index.html-84d8a20b.js" as="script"><link rel="prefetch" href="/space/assets/index.html-b895a076.js" as="script"><link rel="prefetch" href="/space/assets/dash.all.min-3310ca58.js" as="script"><link rel="prefetch" href="/space/assets/mpegts-8aaee227.js" as="script"><link rel="prefetch" href="/space/assets/hls.min-ee146b41.js" as="script"><link rel="prefetch" href="/space/assets/artplayer-baf7584d.js" as="script"><link rel="prefetch" href="/space/assets/browser-21db0a97.js" as="script"><link rel="prefetch" href="/space/assets/register-c34ca700.js" as="script"><link rel="prefetch" href="/space/assets/waline-meta-56fbc549.js" as="script"><link rel="prefetch" href="/space/assets/component-b98b0c77.js" as="script"><link rel="prefetch" href="/space/assets/auto-6adc87e8.js" as="script"><link rel="prefetch" href="/space/assets/index-202a11cb.js" as="script"><link rel="prefetch" href="/space/assets/flowchart-d65a1d8e.js" as="script"><link rel="prefetch" href="/space/assets/mermaid.core-02e974dc.js" as="script"><link rel="prefetch" href="/space/assets/highlight.esm-75b11b9d.js" as="script"><link rel="prefetch" href="/space/assets/markdown.esm-30be9ea9.js" as="script"><link rel="prefetch" href="/space/assets/math.esm-70a288c8.js" as="script"><link rel="prefetch" href="/space/assets/notes.esm-a106bb2c.js" as="script"><link rel="prefetch" href="/space/assets/reveal.esm-1a4c3ae7.js" as="script"><link rel="prefetch" href="/space/assets/search.esm-7e6792e2.js" as="script"><link rel="prefetch" href="/space/assets/zoom.esm-b83b91d0.js" as="script"><link rel="prefetch" href="/space/assets/VuePlayground-a1ffa417.js" as="script"><link rel="prefetch" href="/space/assets/photoswipe.esm-060dc2da.js" as="script"><link rel="prefetch" href="/space/assets/index-e32a7948.js" as="script"><link rel="prefetch" href="/space/assets/pageview-d210658e.js" as="script"><link rel="prefetch" href="/space/assets/index-e32a7948.js" as="script"><link rel="prefetch" href="/space/assets/style-e9220a04.js" as="script"><link rel="prefetch" href="/space/assets/docsearch-1d421ddb.js" as="script"><link rel="prefetch" href="/space/assets/index-82585c84.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><!--[--><div class="theme-container has-toc"><!--[--><header id="navbar" class="vp-navbar"><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><!----><!--]--><!--[--><a class="vp-link vp-brand" href="/space/"><!----><!----><span class="vp-site-name">#/ cd L.H.X Blog Home</span></a><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-center"><!--[--><!----><!--]--><!--[--><nav class="vp-nav-links"><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="博客"><span class="title"><span class="font-icon icon fas fa-book-open" style=""></span>博客</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/space/posts/python/"><span class="font-icon icon fa-brands fa-python" style=""></span>Python<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/space/posts/tools/"><span class="font-icon icon fas fa-toolbox" style=""></span>常用工具<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/space/posts/design_pattern/"><span class="font-icon icon fas fa-code" style=""></span>设计模式<!----></a></li><li class="dropdown-item"><a class="vp-link nav-link" href="/space/posts/gRPC/"><span class="font-icon icon fas fa-book" style=""></span>gRPC<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="人工智能"><span class="title"><span class="font-icon icon fab fa-android" style=""></span>人工智能</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link active" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/"><span class="font-icon icon fab fa-android" style=""></span>大语言模型<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><div class="dropdown-wrapper"><button type="button" class="dropdown-title" aria-label="杂谈"><span class="title"><span class="font-icon icon fab fa-diary" style=""></span>杂谈</span><span class="arrow"></span><ul class="nav-dropdown"><li class="dropdown-item"><a class="vp-link nav-link" href="/space/diary/%E5%B0%8F%E8%AE%B0/"><span class="font-icon icon fab fa-android" style=""></span>日记<!----></a></li></ul></button></div></div><div class="nav-item hide-in-mobile"><a class="vp-link nav-link" href="/space/timeline/"><span class="font-icon icon fas fa-clock" style=""></span>时光轴<!----></a></div></nav><!--]--><!--[--><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><!--]--><!--[--><!----><div class="nav-item vp-repo"><a class="vp-repo-link" href="https://github.com/lianghexiang/space" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="nav-item hide-in-mobile"><button type="button" class="outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="outlook-dropdown"><!----></div></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><!--[--><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar"><!--[--><!----><!--]--><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-heading clickable active" type="button"><!----><span class="vp-sidebar-title">L L M</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><!--[--><a class="vp-link nav-link vp-sidebar-link vp-sidebar-page" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/llm-prompt%E6%8F%90%E7%A4%BA%E5%8E%9F%E5%88%99.html"><span class="font-icon icon fas fa-database" style=""></span>Prompt提示词<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a class="vp-link nav-link vp-sidebar-link vp-sidebar-page" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90RAG.html"><span class="font-icon icon fas fa-database" style=""></span>RAG 简介<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a class="vp-link nav-link vp-sidebar-link vp-sidebar-page" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93.html"><span class="font-icon icon fas fa-database" style=""></span>向量数据库<!----></a><ul class="vp-sidebar-sub-headers"></ul><!--]--></li><li><!--[--><a class="vp-link nav-link active vp-sidebar-link vp-sidebar-page active" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html"><span class="font-icon icon fas fa-database" style=""></span>大语言模型简介<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#_1-llm理论简介"><!---->1.LLM理论简介<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#一、什么是llm"><!---->一、什么是LLM<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#一、什么是大型语言模型-llm"><!---->一、什么是大型语言模型（LLM）<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#_1-1-大型语言模型-llm-的概念"><!---->1.1 大型语言模型（LLM）的概念<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#_1-2-llm-的发展历程"><!---->1.2 LLM 的发展历程<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#_1-3-常见的-llm-模型"><!---->1.3 常见的 LLM 模型<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#二、llm-的能力与特点"><!---->二、LLM 的能力与特点<!----></a><ul class="vp-sidebar-sub-headers"><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#_2-1-llm-的能力"><!---->2.1 LLM 的能力<!----></a><ul class="vp-sidebar-sub-headers"></ul></li><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#_2-2-llm-的特点"><!---->2.2 LLM 的特点<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul></li><li class="vp-sidebar-sub-header"><a class="vp-link nav-link vp-sidebar-link vp-heading" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html#三、llm-的应用与影响"><!---->三、LLM 的应用与影响<!----></a><ul class="vp-sidebar-sub-headers"></ul></li></ul><!--]--></li></ul></section></li></ul><!--[--><!----><!--]--></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><img class="page-cover" src="https://img.tucang.cc/api/image/show/6c8acb93bd0fc9dd85006746d572df8f" alt="大语言模型简介" no-view><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fas fa-database" style=""></span>大语言模型简介</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="/intro.html" target="_blank" rel="noopener noreferrer">L.H.X</a></span><span property="author" content="L.H.X"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span><!----></span><meta property="datePublished" content="2025-01-03T00:00:00.000Z"></span><span class="page-pageview-info" aria-label="访问量🔢" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon eye-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="eye icon"><path d="M992 512.096c0-5.76-.992-10.592-1.28-11.136-.192-2.88-1.152-8.064-2.08-10.816-.256-.672-.544-1.376-.832-2.08-.48-1.568-1.024-3.104-1.6-4.32C897.664 290.112 707.104 160 512 160c-195.072 0-385.632 130.016-473.76 322.592-1.056 2.112-1.792 4.096-2.272 5.856a55.512 55.512 0 00-.64 1.6c-1.76 5.088-1.792 8.64-1.632 7.744-.832 3.744-1.568 11.168-1.568 11.168-.224 2.272-.224 4.032.032 6.304 0 0 .736 6.464 1.088 7.808.128 1.824.576 4.512 1.12 6.976h-.032c.448 2.08 1.12 4.096 1.984 6.08.48 1.536.992 2.976 1.472 4.032C126.432 733.856 316.992 864 512 864c195.136 0 385.696-130.048 473.216-321.696 1.376-2.496 2.24-4.832 2.848-6.912.256-.608.48-1.184.672-1.728 1.536-4.48 1.856-8.32 1.728-8.32l-.032.032c.608-3.104 1.568-7.744 1.568-13.28zM512 672c-88.224 0-160-71.776-160-160s71.776-160 160-160 160 71.776 160 160-71.776 160-160 160z"></path></svg><span id="ArtalkPV" class="waline-pageview-count" data-path="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B.html">...</span></span><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 22 分钟</span><meta property="timeRequired" content="PT22M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item category5 clickable" role="navigation">人工智能</span><!--]--><meta property="articleSection" content="人工智能"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="down"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item tag0 clickable" role="navigation">Prompt</span><span class="page-tag-item tag6 clickable" role="navigation">LLM</span><!--]--><meta property="keywords" content="Prompt,LLM"></span></div><hr></div><div class="toc-place-holder"><aside id="toc"><!--[--><!----><!--]--><div class="toc-header">此页内容<!----></div><div class="toc-wrapper"><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/space/#_1-llm理论简介">1.LLM理论简介</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/space/#一、什么是llm">一、什么是LLM</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/space/#一、什么是大型语言模型-llm">一、什么是大型语言模型（LLM）</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/space/#_1-1-大型语言模型-llm-的概念">1.1 大型语言模型（LLM）的概念</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/space/#_1-2-llm-的发展历程">1.2 LLM 的发展历程</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/space/#_1-3-常见的-llm-模型">1.3 常见的 LLM 模型</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/space/#二、llm-的能力与特点">二、LLM 的能力与特点</a></li><li><ul class="toc-list"><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/space/#_2-1-llm-的能力">2.1 LLM 的能力</a></li><!----><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level3" href="/space/#_2-2-llm-的特点">2.2 LLM 的特点</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="toc-item"><a class="vp-link toc-link level2" href="/space/#三、llm-的应用与影响">三、LLM 的应用与影响</a></li><!----><!--]--></ul><div class="toc-marker" style="top:-1.7rem;"></div></div><!--[--><!----><!--]--></aside></div><!----><div class="theme-hope-content"><h1 id="大语言模型简介" tabindex="-1"><a class="header-anchor" href="#大语言模型简介" aria-hidden="true">#</a> 大语言模型简介</h1><h2 id="_1-llm理论简介" tabindex="-1"><a class="header-anchor" href="#_1-llm理论简介" aria-hidden="true">#</a> 1.LLM理论简介</h2><h3 id="一、什么是llm" tabindex="-1"><a class="header-anchor" href="#一、什么是llm" aria-hidden="true">#</a> 一、什么是LLM</h3><p><strong>大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型</strong>。</p><p>LLM 通常指包含<strong>数百亿（或更多）参数的语言模型</strong>，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。</p><p>为了探索性能的极限，许多研究人员开始训练越来越庞大的语言模型，例如拥有 <code>1750 亿</code>参数的 <code>GPT-3</code> 和 <code>5400 亿</code>参数的 <code>PaLM</code> 。尽管这些大型语言模型与小型语言模型（例如 <code>3.3 亿</code>参数的 <code>BERT</code> 和 <code>15 亿</code>参数的 <code>GPT-2</code>）使用相似的架构和预训练任务，但它们展现出截然不同的能力，尤其在解决复杂任务时表现出了惊人的潜力，这被称为“<strong>涌现能力</strong>”。以 GPT-3 和 GPT-2 为例，GPT-3 可以通过学习上下文来解决少样本任务，而 GPT-2 在这方面表现较差。因此，科研界给这些庞大的语言模型起了个名字，称之为“大语言模型（LLM）”。LLM 的一个杰出应用就是 <strong>ChatGPT</strong> ，它是 GPT 系列 LLM 用于与人类对话式应用的大胆尝试，展现出了非常流畅和自然的表现。</p><h2 id="一、什么是大型语言模型-llm" tabindex="-1"><a class="header-anchor" href="#一、什么是大型语言模型-llm" aria-hidden="true">#</a> 一、什么是大型语言模型（LLM）</h2><h3 id="_1-1-大型语言模型-llm-的概念" tabindex="-1"><a class="header-anchor" href="#_1-1-大型语言模型-llm-的概念" aria-hidden="true">#</a> 1.1 大型语言模型（LLM）的概念</h3><p><strong>大语言模型（LLM，Large Language Model），也称大型语言模型，是一种旨在理解和生成人类语言的人工智能模型</strong>。</p><p>LLM 通常指包含<strong>数百亿（或更多）参数的语言模型</strong>，它们在海量的文本数据上进行训练，从而获得对语言深层次的理解。目前，国外的知名 LLM 有 GPT-3.5、GPT-4、PaLM、Claude 和 LLaMA 等，国内的有文心一言、讯飞星火、通义千问、ChatGLM、百川等。</p><p>为了探索性能的极限，许多研究人员开始训练越来越庞大的语言模型，例如拥有 <code>1750 亿</code>参数的 <code>GPT-3</code> 和 <code>5400 亿</code>参数的 <code>PaLM</code> 。尽管这些大型语言模型与小型语言模型（例如 <code>3.3 亿</code>参数的 <code>BERT</code> 和 <code>15 亿</code>参数的 <code>GPT-2</code>）使用相似的架构和预训练任务，但它们展现出截然不同的能力，尤其在解决复杂任务时表现出了惊人的潜力，这被称为“<strong>涌现能力</strong>”。以 GPT-3 和 GPT-2 为例，GPT-3 可以通过学习上下文来解决少样本任务，而 GPT-2 在这方面表现较差。因此，科研界给这些庞大的语言模型起了个名字，称之为“大语言模型（LLM）”。LLM 的一个杰出应用就是 <strong>ChatGPT</strong> ，它是 GPT 系列 LLM 用于与人类对话式应用的大胆尝试，展现出了非常流畅和自然的表现。</p><h3 id="_1-2-llm-的发展历程" tabindex="-1"><a class="header-anchor" href="#_1-2-llm-的发展历程" aria-hidden="true">#</a> 1.2 LLM 的发展历程</h3><p>语言建模的研究可以追溯到<code>20 世纪 90 年代</code>，当时的研究主要集中在采用<strong>统计学习方法</strong>来预测词汇，通过分析前面的词汇来预测下一个词汇。但在理解复杂语言规则方面存在一定局限性。</p><p>随后，研究人员不断尝试改进，<code>2003 年</code>深度学习先驱 <strong>Bengio</strong> 在他的经典论文 <code>《A Neural Probabilistic Language Model》</code>中，首次将深度学习的思想融入到语言模型中。强大的<strong>神经网络模型</strong>，相当于为计算机提供了强大的&quot;大脑&quot;来理解语言，让模型可以更好地捕捉和理解语言中的复杂关系。</p><p><code>2018 年</code>左右，<strong>Transformer 架构的神经网络模型</strong>开始崭露头角。通过大量文本数据训练这些模型，使它们能够通过阅读大量文本来深入理解语言规则和模式，就像让计算机阅读整个互联网一样，对语言有了更深刻的理解，极大地提升了模型在各种自然语言处理任务上的表现。</p><p>与此同时，研究人员发现，随着<strong>语言模型规模的扩大（增加模型大小或使用更多数据）</strong>，模型展现出了一些惊人的能力，在各种任务中的表现均显著提升。这一发现标志着大型语言模型（LLM）时代的开启。</p><h3 id="_1-3-常见的-llm-模型" tabindex="-1"><a class="header-anchor" href="#_1-3-常见的-llm-模型" aria-hidden="true">#</a> 1.3 常见的 LLM 模型</h3><p>大语言模型的发展历程虽然只有短短不到五年的时间，但是发展速度相当惊人，截止 2023 年 6 月，国内外有超过百种大模型相继发布。下图按照时间线给出了 2019 年至 2023 年 6 月比较有影响力并且模型参数量超过 100 亿的大语言模型：</p><figure><img src="https://datawhalechina.github.io/figures/C1-1-LLMs_0623_final.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>（该图来源于参考内容 [<a href="https://arxiv.org/abs/2303.18223" target="_blank" rel="noopener noreferrer">1<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>]）</p><p>接下来我们主要介绍几个国内外常见的大模型（包括开源和闭源）</p><h4 id="_1-3-1-闭源-llm-未公开源代码" tabindex="-1"><a class="header-anchor" href="#_1-3-1-闭源-llm-未公开源代码" aria-hidden="true">#</a> 1.3.1 闭源 LLM (未公开源代码)</h4><h5 id="_1-3-1-1-gpt-系列" tabindex="-1"><a class="header-anchor" href="#_1-3-1-1-gpt-系列" aria-hidden="true">#</a> 1.3.1.1 GPT 系列</h5><blockquote><p><a href="https://platform.openai.com/docs/models" target="_blank" rel="noopener noreferrer">OpenAI 模型介绍<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p><strong>OpenAI</strong> 公司在 <code>2018 年</code>提出的 <strong>GPT（Generative Pre-Training）</strong> 模型是典型的 <code>生成式预训练语言模型</code> 之一。</p><p>GPT 模型的基本原则是<strong>通过语言建模将世界知识压缩到仅解码器 (decoder-only) 的 Transformer 模型中</strong>，这样它就可以恢复(或记忆)世界知识的语义，并充当通用任务求解器。它能够成功的两个关键点：</p><ul><li>训练能够准确预测下一个单词的 decoder-only 的 Transformer 语言模型</li><li>扩展语言模型的大小</li></ul><p>OpenAI 在 LLM 上的研究大致可以分为以下几个阶段：</p><figure><img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-GPT_series.png" alt="GPT 阶段" tabindex="0" loading="lazy"><figcaption>GPT 阶段</figcaption></figure><p>接下来，我们将从模型规模、特点等方面，介绍大家熟知的 ChatGPT 与 GPT4：</p><h6 id="_1-3-1-1-1-chatgpt-https-datawhalechina-github-io-llm-universe-c1-1-大语言模型-llm-理论简介-id-13111-chatgpt" tabindex="-1"><a class="header-anchor" href="#_1-3-1-1-1-chatgpt-https-datawhalechina-github-io-llm-universe-c1-1-大语言模型-llm-理论简介-id-13111-chatgpt" aria-hidden="true">#</a> [1.3.1.1.1 ChatGPT](<a href="https://datawhalechina.github.io/llm-universe/#/C1/1.%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B" target="_blank" rel="noopener noreferrer">https://datawhalechina.github.io/llm-universe/#/C1/1.大语言模型<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a> LLM 理论简介?id=_13111-chatgpt)</h6><blockquote><p><a href="https://chat.openai.com/" target="_blank" rel="noopener noreferrer">ChatGPT 使用地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p><code>2022 年 11 月</code>，<strong>OpenAI</strong> 发布了基于 GPT 模型（GPT-3.5 和 GPT-4） 的<strong>会话应用 ChatGPT</strong>。由于与人类交流的出色能力，ChatGPT 自发布以来就引发了人工智能社区的兴奋。ChatGPT 是基于强大的 GPT 模型开发的，具有特别优化的会话能力。</p><p>ChatGPT 从本质上来说是一个 LLM 应用，是基于基座模型开发出来的，与基座模型有本质的区别。其支持 GPT-3.5 和 GPT-4 两个版本。</p><figure><img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-ChatGPT.png" alt="ChatGPT 界面" tabindex="0" loading="lazy"><figcaption>ChatGPT 界面</figcaption></figure><p>现在的 ChatGPT 支持最长达 32,000 个字符，知识截止日期是 2021 年 9 月，它可以执行各种任务，包括<strong>代码编写、数学问题求解、写作建议</strong>等。ChatGPT 在与人类交流方面表现出了卓越的能力：拥有丰富的知识储备，对数学问题进行推理的技能，在多回合对话中准确追踪上下文，并且与人类安全使用的价值观非常一致。后来，ChatGPT 支持插件机制，这进一步扩展了 ChatGPT 与现有工具或应用程序的能力。到目前为止，它似乎是人工智能历史上最强大的聊天机器人。ChatGPT 的推出对未来的人工智能研究具有重大影响，它为探索类人人工智能系统提供了启示。</p><h6 id="_1-3-1-1-2-gpt-4" tabindex="-1"><a class="header-anchor" href="#_1-3-1-1-2-gpt-4" aria-hidden="true">#</a> 1.3.1.1.2 GPT-4</h6><p><code>2023 年 3 月</code>发布的 GPT-4，它将<strong>文本输入扩展到多模态信号</strong>。GPT3.5 拥有 1750 亿 个参数，而 GPT4 的参数量官方并没有公布，但有相关人员猜测，GPT-4 在 120 层中总共包含了 1.8 万亿参数，也就是说，GPT-4 的规模是 GPT-3 的 10 倍以上。因此，GPT-4 比 GPT-3.5 <strong>解决复杂任务的能力更强，在许多评估任务上表现出较大的性能提升</strong>。</p><p>最近的一项研究通过对人为生成的问题进行定性测试来研究 GPT-4 的能力，这些问题包含了各种各样的困难任务，并表明 GPT-4 可以比之前的 GPT 模型(如 GPT3.5 )实现更优越的性能。此外，由于六个月的迭代校准(在 RLHF 训练中有额外的安全奖励信号)，GPT-4 对恶意或挑衅性查询的响应更安全，并应用了一些干预策略来缓解 LLM 可能出现的问题，如幻觉、隐私和过度依赖。</p><blockquote><p>注意：2023 年 11 月 7 日， OpenAI 召开了首个开发者大会，会上推出了最新的大语言模型 GPT-4 Turbo，Turbo 相当于进阶版。它将上下文长度扩展到 128k，相当于 300 页文本，并且训练知识更新到 2023 年 4 月</p></blockquote><p>GPT3.5 是免费的，而 GPT-4 是收费的。需要开通 plus 会员 20 美元/月。</p><p><code>2024 年 5 月 14 日</code>，新一代旗舰生成模型 <strong>GPT-4o</strong> 正式发布。GPT-4o 具备了对文本、语音、图像三种模态的深度理解能力，反应迅速且富有情感色彩，极具人性化。而且 GPT-4o 是完全免费的，虽然每天的免费使用次数是有限的。</p><p>通常我们可以调用模型 API 来开发自己的应用，主流模型 <a href="https://openai.com/pricing" target="_blank" rel="noopener noreferrer">API 对比<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>如下：</p><table><thead><tr><th>语言模型名称</th><th>上下文长度</th><th>特点</th><th>input 费用($/million tokens)</th><th>output 费用($/ 1M tokens)</th><th>知识截止日期</th></tr></thead><tbody><tr><td>GPT-3.5-turbo-0125</td><td>16k</td><td>经济，专门对话</td><td>0.5</td><td>1.5</td><td>2021 年 9 月</td></tr><tr><td>GPT-3.5-turbo-instruct</td><td>4k</td><td>指令模型</td><td>1.5</td><td>2</td><td>2021 年 9 月</td></tr><tr><td>GPT-4</td><td>8k</td><td>性能更强</td><td>30</td><td>60</td><td>2021 年 9 月</td></tr><tr><td>GPT-4-32k</td><td>32k</td><td>性能强，长上下文</td><td>60</td><td>120</td><td>2021 年 9 月</td></tr><tr><td>GPT-4-turbo</td><td>128k</td><td>性能更强</td><td>10</td><td>30</td><td>2023 年 12 月</td></tr><tr><td>GPT-4o</td><td>128k</td><td>性能最强，速度更快</td><td>5</td><td>15</td><td>2023 年 10 月</td></tr></tbody></table><table><thead><tr><th>Embedding 模型名称</th><th>维度</th><th>特点</th><th>费用($/ 1M tokens)</th></tr></thead><tbody><tr><td>text-embedding-3-small</td><td>512/1536</td><td>较小</td><td>0.02</td></tr><tr><td>text-embedding-3-large</td><td>256/1024/3072</td><td>较大</td><td>0.13</td></tr><tr><td>ada v2</td><td>1536</td><td>传统</td><td>0.1</td></tr></tbody></table><h5 id="_1-3-1-2-claude-系列" tabindex="-1"><a class="header-anchor" href="#_1-3-1-2-claude-系列" aria-hidden="true">#</a> 1.3.1.2 Claude 系列</h5><p>Claude 系列模型是由 OpenAI 离职人员创建的 <strong>Anthropic</strong> 公司开发的闭源语言大模型。</p><blockquote><p><a href="https://claude.ai/chats" target="_blank" rel="noopener noreferrer">Claude 使用地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>最早的 <strong>Claude</strong> 于 <code>2023 年 3 月 15 日</code>发布，在 2023 年 7 月 11 日，更新至 <strong>Claude-2</strong>， 并在 <code>2024 年 3 月 4 日</code>更新至 <strong>Claude-3</strong>。</p><p>Claude 3 系列包括三个不同的模型，分别是 Claude 3 Haiku、Claude 3 Sonnet 和 Claude 3 Opus，它们的能力依次递增，旨在满足不同用户和应用场景的需求。</p><table><thead><tr><th>模型名称</th><th>上下文长度</th><th>特点</th><th>input 费用($/1M tokens)</th><th>output 费用($/1M tokens)</th></tr></thead><tbody><tr><td>Claude 3 Haiku</td><td>200k</td><td>速度最快</td><td>0.25</td><td>1.25</td></tr><tr><td>Claude 3 Sonnet</td><td>200k</td><td>平衡</td><td>3</td><td>15</td></tr><tr><td>Claude 3 Opus</td><td>200k</td><td>性能最强</td><td>15</td><td>75</td></tr></tbody></table><figure><img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-Claude.png" alt="Claude 界面" tabindex="0" loading="lazy"><figcaption>Claude 界面</figcaption></figure><h5 id="_1-3-1-1-3-palm-gemini-系列" tabindex="-1"><a class="header-anchor" href="#_1-3-1-1-3-palm-gemini-系列" aria-hidden="true">#</a> 1.3.1.1.3 PaLM/Gemini 系列</h5><p><strong>PaLM 系列</strong>语言大模型由 <strong>Google</strong> 开发。其初始版本于 <code>2022 年 4 月</code>发布，并在 2023 年 3 月公开了 API。2023 年 5 月，Google 发布了 <strong>PaLM 2</strong>，<code>2024 年 2 月 1 日</code>，Google 将 Bard(之前发布的对话应用) 的底层大模型驱动由 PaLM2 更改为 <strong>Gemini</strong>，同时也将原先的 Bard 更名为 <strong>Gemini</strong>。</p><blockquote><p><a href="https://ai.google/discover/palm2/" target="_blank" rel="noopener noreferrer">PaLM 官方地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><blockquote><p><a href="https://gemini.google.com/" target="_blank" rel="noopener noreferrer">Gemini 使用地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p>目前的 Gemini 是第一个版本，即 Gemini 1.0，根据参数量不同分为 Ultra, Pro 和 Nano 三个版本。</p><p>以下窗口是 Gemini 的界面:</p><figure><img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-Gemini.png" alt="Gemini 界面" tabindex="0" loading="lazy"><figcaption>Gemini 界面</figcaption></figure><h5 id="_1-3-1-1-4-文心一言" tabindex="-1"><a class="header-anchor" href="#_1-3-1-1-4-文心一言" aria-hidden="true">#</a> 1.3.1.1.4 文心一言</h5><blockquote><p><a href="https://yiyan.baidu.com/" target="_blank" rel="noopener noreferrer">文心一言使用地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p><strong>文心一言是基于百度文心大模型的知识增强语言大模型</strong>，于 <code>2023 年 3 月</code>在国内率先开启邀测。文心一言的基础模型文心大模型于 2019 年发布 1.0 版，现已更新到 <strong>4.0</strong> 版本。更进一步划分，文心大模型包括 NLP 大模型、CV 大模型、跨模态大模型、生物计算大模型、行业大模型。中文能力相对来说非常不错的闭源模型。</p><p>文心一言网页版分为<strong>免费版</strong>和<strong>专业版</strong>。</p><ul><li>免费版使用文心 3.5 版本，已经能够满足个人用户或小型企业的大部分需求。</li><li>专业版使用文心 4.0 版本。定价为 59.9 元/月，连续包月优惠价为 49.9 元/月</li></ul><p>同时也可以使用 API 进行调用（<a href="https://console.bce.baidu.com/qianfan/chargemanage/list" target="_blank" rel="noopener noreferrer">计费详情<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a>）。</p><p>以下是文心一言的使用界面：</p><figure><img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-yiyan.png" alt="文心一言界面" tabindex="0" loading="lazy"><figcaption>文心一言界面</figcaption></figure><h5 id="_1-3-1-1-5-星火大模型" tabindex="-1"><a class="header-anchor" href="#_1-3-1-1-5-星火大模型" aria-hidden="true">#</a> 1.3.1.1.5 星火大模型</h5><blockquote><p><a href="https://xinghuo.xfyun.cn/" target="_blank" rel="noopener noreferrer">星火大模型使用地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p><strong>讯飞星火认知大模型</strong>是<strong>科大讯飞</strong>发布的语言大模型，支持多种自然语言处理任务。该模型于 <code>2023 年 5 月</code>首次发布，后续经过多次升级。<code>2023 年 10 月</code>，讯飞发布了<strong>讯飞星火认知大模型 V3.0</strong>。<code>2024 年 1 月</code>，讯飞发布了<strong>讯飞星火认知大模型 V3.5</strong>，在语言理解，文本生成，知识问答等七个方面进行了升级，并且支持 system 指令，插件调用等多项功能。</p><figure><img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-xunfei.jpg" alt="讯飞发布会" tabindex="0" loading="lazy"><figcaption>讯飞发布会</figcaption></figure><p>以下是讯飞星火的使用界面：</p><figure><img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-xinghuo.png" alt="讯飞星火界面" tabindex="0" loading="lazy"><figcaption>讯飞星火界面</figcaption></figure><h4 id="_1-3-2-开源-llm" tabindex="-1"><a class="header-anchor" href="#_1-3-2-开源-llm" aria-hidden="true">#</a> 1.3.2. 开源 LLM]</h4><h5 id="_1-3-2-1-llama-系列" tabindex="-1"><a class="header-anchor" href="#_1-3-2-1-llama-系列" aria-hidden="true">#</a> 1.3.2.1 LLaMA 系列</h5><blockquote><p><a href="https://llama.meta.com/" target="_blank" rel="noopener noreferrer">LLaMA 官方地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><blockquote><p><a href="https://github.com/facebookresearch/llama" target="_blank" rel="noopener noreferrer">LLaMA 开源地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p><strong>LLaMA 系列模型</strong>是 <strong>Meta</strong> 开源的一组参数规模 <strong>从 7B 到 70B</strong> 的基础语言模型。LLaMA 于<code>2023 年 2 月</code>发布，2023 年 7 月发布了 LLaMA2 模型，并于 <code>2024 年 4 月 18 日</code>发布了 <strong>LLaMA3</strong> 模型。它们都是在数万亿个字符上训练的，展示了如何<strong>仅使用公开可用的数据集来训练最先进的模型</strong>，而不需要依赖专有或不可访问的数据集。这些数据集包括 Common Crawl、Wikipedia、OpenWebText2、RealNews、Books 等。LLaMA 模型使用了<strong>大规模的数据过滤和清洗技术</strong>，以提高数据质量和多样性，减少噪声和偏见。LLaMA 模型还使用了高效的<strong>数据并行</strong>和<strong>流水线并行</strong>技术，以加速模型的训练和扩展。特别地，LLaMA 13B 在 CommonsenseQA 等 9 个基准测试中超过了 GPT-3 (175B)，而 <strong>LLaMA 65B 与最优秀的模型 Chinchilla-70B 和 PaLM-540B 相媲美</strong>。LLaMA 通过使用更少的字符来达到最佳性能，从而在各种推理预算下具有优势。</p><p>与 GPT 系列相同，LLaMA 模型也采用了 <strong>decoder-only</strong> 架构，同时结合了一些前人工作的改进：</p><ul><li><code>Pre-normalization 正则化</code>：为了提高训练稳定性，LLaMA 对每个 Transformer 子层的输入进行了 RMSNorm 归一化，这种归一化方法可以避免梯度爆炸和消失的问题，提高模型的收敛速度和性能；</li><li><code>SwiGLU 激活函数</code>：将 ReLU 非线性替换为 SwiGLU 激活函数，增加网络的表达能力和非线性，同时减少参数量和计算量；</li><li><code>旋转位置编码（RoPE，Rotary Position Embedding）</code>：模型的输入不再使用位置编码，而是在网络的每一层添加了位置编码，RoPE 位置编码可以有效地捕捉输入序列中的相对位置信息，并且具有更好的泛化能力。</li></ul><p><strong>LLaMA3</strong> 在 LLaMA 系列模型的基础上进行了改进，提高了模型的性能和效率：</p><ul><li><code>更多的训练数据量</code>：LLaMA3 在 15 万亿个 token 的数据上进行预训练，相比 LLaMA2 的训练数据量增加了 7 倍，且代码数据增加了 4 倍。LLaMA3 能够接触到更多的文本信息，从而提高了其理解和生成文本的能力。</li><li><code>更长的上下文长度</code>：LLaMA3 的上下文长度增加了一倍，从 LLaMA2 的 4096 个 token 增加到了 8192。这使得 LLaMA3 能够处理更长的文本序列，改善了对长文本的理解和生成能力。</li><li><code>分组查询注意力（GQA，Grouped-Query Attention）</code>：通过将查询（query）分组并在组内共享键（key）和值（value），减少了计算量，同时保持了模型性能，提高了大型模型的推理效率（LLaMA2 只有 70B 采用）。</li><li><code>更大的词表</code>：LLaMA3 升级为了 128K 的 tokenizer，是前两代 32K 的 4 倍，这使得其语义编码能力得到了极大的增强，从而显著提升了模型的性能。</li></ul><h5 id="_1-3-2-2-通义千问" tabindex="-1"><a class="header-anchor" href="#_1-3-2-2-通义千问" aria-hidden="true">#</a> 1.3.2.2 通义千问</h5><blockquote><p><a href="https://tongyi.aliyun.com/" target="_blank" rel="noopener noreferrer">通义千问使用地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><blockquote><p><a href="https://github.com/QwenLM/Qwen2" target="_blank" rel="noopener noreferrer">通义千问开源地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p><strong>通义千问由阿里巴巴基于“通义”大模型研发</strong>，于 <code>2023 年 4 月</code>正式发布。2023 年 9 月，阿里云开源了 Qwen（通义千问）系列工作。2024 年 2 月 5 日，开源了 <strong>Qwen1.5</strong>（Qwen2 的测试版）。并于 <code>2024 年 6 月 6 日</code>正式开源了 <strong>Qwen2</strong>。 Qwen2 是一个 <strong>decoder-Only</strong> 的模型，采用 <code>SwiGLU 激活</code>、<code>RoPE</code>、<code>GQA</code>的架构。中文能力相对来说非常不错的开源模型。</p><p>目前，已经开源了 5 种模型大小：<strong>0.5B、1.5B、7B、72B 的 Dense 模型和 57B (A14B)的 MoE 模型</strong>；所有模型均支持长度为 <strong>32768 token</strong> 的上下文。并将 Qwen2-7B-Instruct 和 Qwen2-72B-Instruct 的上下文长度扩展至 <strong>128K token</strong>。</p><p>以下是通义千问的使用界面： <img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-qwen.png" alt="通义千问界面" loading="lazy"></p><h5 id="_1-3-2-3-glm-系列" tabindex="-1"><a class="header-anchor" href="#_1-3-2-3-glm-系列" aria-hidden="true">#</a> 1.3.2.3 GLM 系列</h5><blockquote><p><a href="https://chatglm.cn/" target="_blank" rel="noopener noreferrer">ChatGLM 使用地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><blockquote><p><a href="https://github.com/THUDM/GLM-4" target="_blank" rel="noopener noreferrer">ChatGLM 开源地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p><strong>GLM 系列模型</strong>是<strong>清华大学和智谱 AI 等</strong>合作研发的语言大模型。2023 年 3 月 发布了 <strong>ChatGLM</strong>。6 月发布了 <strong>ChatGLM 2</strong>。10 月推出了 <strong>ChatGLM3</strong>。2024 年 1 月 16 日 发布了 <strong>GLM4</strong>，并于 <code>2024 年 6 月 6 日</code>正式开源。</p><p><strong>GLM-4-9B-Chat</strong> 支持多轮对话的同时，还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理（支持最大 <strong>128K</strong> 上下文）等功能。</p><p>开源了<code>对话模型</code> <strong>GLM-4-9B-Chat</strong>、<code>基础模型</code> <strong>GLM-4-9B</strong>、<code>长文本对话模型</code> <strong>GLM-4-9B-Chat-1M</strong>（支持 1M 上下文长度）、<code>多模态模型</code><strong>GLM-4V-9B</strong> 等全面对标 OpenAI：</p><figure><img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-chatglm_vs_openai.png" alt="chatglm VS openai" tabindex="0" loading="lazy"><figcaption>chatglm VS openai</figcaption></figure><p>以下是智谱清言的使用界面：</p><figure><img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-chatglm.png" alt="智谱清言界面" tabindex="0" loading="lazy"><figcaption>智谱清言界面</figcaption></figure><h5 id="_1-3-2-4-baichuan-系列" tabindex="-1"><a class="header-anchor" href="#_1-3-2-4-baichuan-系列" aria-hidden="true">#</a> 1.3.2.4 Baichuan 系列</h5><blockquote><p><a href="https://www.baichuan-ai.com/chat" target="_blank" rel="noopener noreferrer">百川使用地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><blockquote><p><a href="https://github.com/baichuan-inc" target="_blank" rel="noopener noreferrer">百川开源地址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></blockquote><p><strong>Baichuan</strong> 是由<strong>百川智能</strong>开发的<strong>开源可商用</strong>的语言大模型。其基于<strong>Transformer 解码器架构（decoder-only）</strong>。</p><p>2023 年 6 月 15 日发布了 <strong>Baichuan-7B</strong> 和 <strong>Baichuan-13B</strong>。百川同时开源了<strong>预训练</strong>和<strong>对齐</strong>模型，<code>预训练模型是面向开发者的“基座”</code>，而<code>对齐模型则面向广大需要对话功能的普通用户</code>。</p><p><strong>Baichuan2</strong> 于 <code>2023年 9 月 6 日</code>推出。发布了 <strong>7B、13B</strong> 的 <strong>Base</strong> 和 <strong>Chat</strong> 版本，并提供了 Chat 版本的 <strong>4bits 量化</strong>。</p><p><code>2024 年 1 月 29 日</code> 发布了 <strong>Baichuan 3</strong>。但是<strong>目前还没有开源</strong>。</p><p>以下是百川大模型的使用界面： <img src="https://datawhalechina.github.io/llm-universe/figures/C1-1-baichuan.png" alt="百川界面" loading="lazy"></p><h2 id="二、llm-的能力与特点" tabindex="-1"><a class="header-anchor" href="#二、llm-的能力与特点" aria-hidden="true">#</a> 二、LLM 的能力与特点</h2><h3 id="_2-1-llm-的能力" tabindex="-1"><a class="header-anchor" href="#_2-1-llm-的能力" aria-hidden="true">#</a> 2.1 LLM 的能力</h3><h4 id="_2-1-1-涌现能力-emergent-abilities" tabindex="-1"><a class="header-anchor" href="#_2-1-1-涌现能力-emergent-abilities" aria-hidden="true">#</a> 2.1.1 涌现能力（emergent abilities）</h4><p>区分大语言模型（LLM）与以前的预训练语言模型（PLM）最显著的特征之一是它们的 <code>涌现能力</code> 。涌现能力是一种令人惊讶的能力，它在小型模型中不明显，但在大型模型中特别突出。类似物理学中的相变现象，涌现能力就像是模型性能随着规模增大而迅速提升，超过了随机水平，也就是我们常说的<strong>量变引起质变</strong>。</p><p>涌现能力可以与某些复杂任务有关，但我们更关注的是其通用能力。接下来，我们简要介绍三个 LLM 典型的涌现能力：</p><ol><li><strong>上下文学习</strong>：上下文学习能力是由 GPT-3 首次引入的。这种能力允许语言模型在提供自然语言指令或多个任务示例的情况下，通过理解上下文并生成相应输出的方式来执行任务，而无需额外的训练或参数更新。</li><li><strong>指令遵循</strong>：通过使用自然语言描述的多任务数据进行微调，也就是所谓的 <code>指令微调</code>。LLM 被证明在使用指令形式化描述的未见过的任务上表现良好。这意味着 LLM 能够根据任务指令执行任务，而无需事先见过具体示例，展示了其强大的泛化能力。</li><li><strong>逐步推理</strong>：小型语言模型通常难以解决涉及多个推理步骤的复杂任务，例如数学问题。然而，LLM 通过采用 <code>思维链（CoT, Chain of Thought）</code> 推理策略，利用包含中间推理步骤的提示机制来解决这些任务，从而得出最终答案。据推测，这种能力可能是通过对代码的训练获得的。</li></ol><p>这些涌现能力让 LLM 在处理各种任务时表现出色，使它们成为了解决复杂问题和应用于多领域的强大工具。</p><h4 id="_2-1-2-作为基座模型支持多元应用的能力" tabindex="-1"><a class="header-anchor" href="#_2-1-2-作为基座模型支持多元应用的能力" aria-hidden="true">#</a> 2.1.2 作为基座模型支持多元应用的能力</h4><p>在 2021 年，斯坦福大学等多所高校的研究人员提出了基座模型（foundation model）的概念，清晰了预训练模型的作用。这是一种全新的 AI 技术范式，借助于海量无标注数据的训练，获得可以适用于大量下游任务的大模型（单模态或者多模态）。这样，<strong>多个应用可以只依赖于一个或少数几个大模型进行统一建设</strong>。</p><p>大语言模型是这个新模式的典型例子，使用统一的大模型可以极大地提高研发效率。相比于每次开发单个模型的方式，这是一项本质上的进步。大型模型不仅可以缩短每个具体应用的开发周期，减少所需人力投入，也可以基于大模型的推理、常识和写作能力，获得更好的应用效果。因此，大模型可以成为 AI 应用开发的大一统基座模型，这是一个一举多得、全新的范式，值得大力推广。</p><h4 id="_2-1-3-支持对话作为统一入口的能力" tabindex="-1"><a class="header-anchor" href="#_2-1-3-支持对话作为统一入口的能力" aria-hidden="true">#</a> 2.1.3 支持对话作为统一入口的能力</h4><p>让大语言模型真正火爆的契机，是基于对话聊天的 <strong>ChatGPT</strong>。业界很早就发现了用户对于对话交互的特殊偏好，陆奇在微软期间，就于 2016 年推进过“对话即平台（conversation as a platform）” 的战略。此外，苹果 Siri 、亚马逊 Echo 等基于语音对话的产品也非常受欢迎，反映出互联网用户对于聊天和对话这种交互模式的偏好。虽然之前的聊天机器人存在各种问题，但大型语言模型的出现再次让聊天机器人这种交互模式可以重新涌现。用户愈发期待像钢铁侠中“贾维斯”一样的人工智能，无所不能、无所不知。这引发我们对于<code>智能体（Agent）</code>类型应用前景的思考，Auto-GPT、微软 Jarvis 等项目已经出现并受到关注，相信未来会涌现出很多类似的以对话形态让助手完成各种具体工作的项目。</p><h3 id="_2-2-llm-的特点" tabindex="-1"><a class="header-anchor" href="#_2-2-llm-的特点" aria-hidden="true">#</a> 2.2 LLM 的特点</h3><p>大语言模型具有多种显著特点，这些特点使它们在自然语言处理和其他领域中引起了广泛的兴趣和研究。以下是大语言模型的一些主要特点：</p><ol><li><strong>巨大的规模：</strong> LLM 通常具有巨大的参数规模，可以达到数十亿甚至数千亿个参数。这使得它们能够捕捉更多的语言知识和复杂的语法结构。</li><li><strong>预训练和微调：</strong> LLM 采用了预训练和微调的学习方法。首先在大规模文本数据上进行预训练（无标签数据），学习通用的语言表示和知识。然后通过微调（有标签数据）适应特定任务，从而在各种 NLP 任务中表现出色。</li><li><strong>上下文感知：</strong> LLM 在处理文本时具有强大的上下文感知能力，能够理解和生成依赖于前文的文本内容。这使得它们在对话、文章生成和情境理解方面表现出色。</li><li><strong>多语言支持：</strong> LLM 可以用于多种语言，不仅限于英语。它们的多语言能力使得跨文化和跨语言的应用变得更加容易。</li><li><strong>多模态支持：</strong> 一些 LLM 已经扩展到支持多模态数据，包括文本、图像和声音。使得它们可以理解和生成不同媒体类型的内容，实现更多样化的应用。</li><li><strong>伦理和风险问题：</strong> 尽管 LLM 具有出色的能力，但它们也引发了伦理和风险问题，包括生成有害内容、隐私问题、认知偏差等。因此，研究和应用 LLM 需要谨慎。</li><li><strong>高计算资源需求：</strong> LLM 参数规模庞大，需要大量的计算资源进行训练和推理。通常需要使用高性能的 GPU 或 TPU 集群来实现。</li></ol><p>大语言模型是一种具有强大语言处理能力的技术，已经在多个领域展示了潜力。它们为自然语言理解和生成任务提供了强大的工具，同时也引发了对其伦理和风险问题的关注。这些特点使 LLM 成为了当今计算机科学和人工智能领域的重要研究和应用方向</p><h2 id="三、llm-的应用与影响" tabindex="-1"><a class="header-anchor" href="#三、llm-的应用与影响" aria-hidden="true">#</a> 三、LLM 的应用与影响</h2><p>LLM 已经在许多领域产生了深远的影响。在<strong>自然语言处理</strong>领域，它可以帮助计算机更好地理解和生成文本，包括写文章、回答问题、翻译语言等。在<strong>信息检索</strong>领域，它可以改进搜索引擎，让我们更轻松地找到所需的信息。在<strong>计算机视觉</strong>领域，研究人员还在努力让计算机理解图像和文字，以改善多媒体交互。</p><p>最重要的是，LLM 的出现让人们重新思考了 <strong>通用人工智能（AGI）</strong> 的可能性。AGI 是一种像人类一样思考和学习的人工智能。LLM 被认为是 AGI 的一种早期形式，这引发了对未来人工智能发展的许多思考和计划。</p><p>总之，LLM 是一种令人兴奋的技术，它让计算机更好地理解和使用语言，正在改变着我们与技术互动的方式，同时也引发了对未来人工智能的无限探索。</p><blockquote><p>在下一章我们将介绍 LLM 时期一个重要的技术 RAG。</p></blockquote><p>【<strong>参考内容</strong>】：</p><ol><li><a href="https://arxiv.org/abs/2303.18223" target="_blank" rel="noopener noreferrer">A Survey of Large Language Models<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li><a href="https://xueqiu.com/1389978604/248392718" target="_blank" rel="noopener noreferrer">周枫：当我们谈论大模型时，应该关注哪些新能力？<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li></ol></div><!----><footer class="page-meta"><div class="meta-item edit-link"><a href="https://github.com/lianghexiang/space/edit/main/src/人工智能/LLM/大语言模型简介.md" rel="noopener noreferrer" target="_blank" aria-label="在GitHub上编辑此文章" class="nav-link label"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在GitHub上编辑此文章<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span><!----></a></div><div class="meta-item git-info"><div class="update-time"><span class="label">上次编辑于: </span><!----></div><div class="contributors"><span class="label">贡献者: </span><!--[--><!--[--><span class="contributor" title="email: lhx110396@163.com">lianghexiang</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="vp-link nav-link prev" href="/space/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/LLM/%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93.html"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><span class="font-icon icon fas fa-database" style=""></span>向量数据库</div></a><!----></nav><div id="comment" class="waline-wrapper" darkmode="false" style="display:block;"><div data-waline provider="Waline"><!--v-if--><div class="wl-comment"><!--v-if--><div class="wl-panel"><div class="wl-header item3"><!--[--><div class="wl-header-item"><label for="wl-nick">昵称</label><input id="wl-nick" class="wl-input wl-nick" name="nick" type="text" value></div><div class="wl-header-item"><label for="wl-mail">邮箱</label><input id="wl-mail" class="wl-input wl-mail" name="mail" type="email" value></div><div class="wl-header-item"><label for="wl-link">网址</label><input id="wl-link" class="wl-input wl-link" name="link" type="text" value></div><!--]--></div><textarea id="wl-edit" class="wl-editor" placeholder="请留言。(填写邮箱可在被回复时收到邮件提醒)"></textarea><div class="wl-preview" style="display:none;"><hr><h4>预览:</h4><div class="wl-content"></div></div><div class="wl-footer"><div class="wl-actions"><a href="https://guides.github.com/features/mastering-markdown/" title="Markdown Guide" aria-label="Markdown is supported" class="wl-action" target="_blank" rel="noopener noreferrer"><svg width="16" height="16" ariaHidden="true"><path d="M14.85 3H1.15C.52 3 0 3.52 0 4.15v7.69C0 12.48.52 13 1.15 13h13.69c.64 0 1.15-.52 1.15-1.15v-7.7C16 3.52 15.48 3 14.85 3zM9 11H7V8L5.5 9.92 4 8v3H2V5h2l1.5 2L7 5h2v6zm2.99.5L9.5 8H11V5h2v3h1.5l-2.51 3.5z" fill="currentColor"></path></svg></a><button type="button" class="wl-action" title="表情" style="display:none;"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M563.2 463.3 677 540c1.7 1.2 3.7 1.8 5.8 1.8.7 0 1.4-.1 2-.2 2.7-.5 5.1-2.1 6.6-4.4l25.3-37.8c1.5-2.3 2.1-5.1 1.6-7.8s-2.1-5.1-4.4-6.6l-73.6-49.1 73.6-49.1c2.3-1.5 3.9-3.9 4.4-6.6.5-2.7 0-5.5-1.6-7.8l-25.3-37.8a10.1 10.1 0 0 0-6.6-4.4c-.7-.1-1.3-.2-2-.2-2.1 0-4.1.6-5.8 1.8l-113.8 76.6c-9.2 6.2-14.7 16.4-14.7 27.5.1 11 5.5 21.3 14.7 27.4zM387 348.8h-45.5c-5.7 0-10.4 4.7-10.4 10.4v153.3c0 5.7 4.7 10.4 10.4 10.4H387c5.7 0 10.4-4.7 10.4-10.4V359.2c0-5.7-4.7-10.4-10.4-10.4zm333.8 241.3-41-20a10.3 10.3 0 0 0-8.1-.5c-2.6.9-4.8 2.9-5.9 5.4-30.1 64.9-93.1 109.1-164.4 115.2-5.7.5-9.9 5.5-9.5 11.2l3.9 45.5c.5 5.3 5 9.5 10.3 9.5h.9c94.8-8 178.5-66.5 218.6-152.7 2.4-5 .3-11.2-4.8-13.6zm186-186.1c-11.9-42-30.5-81.4-55.2-117.1-24.1-34.9-53.5-65.6-87.5-91.2-33.9-25.6-71.5-45.5-111.6-59.2-41.2-14-84.1-21.1-127.8-21.1h-1.2c-75.4 0-148.8 21.4-212.5 61.7-63.7 40.3-114.3 97.6-146.5 165.8-32.2 68.1-44.3 143.6-35.1 218.4 9.3 74.8 39.4 145 87.3 203.3.1.2.3.3.4.5l36.2 38.4c1.1 1.2 2.5 2.1 3.9 2.6 73.3 66.7 168.2 103.5 267.5 103.5 73.3 0 145.2-20.3 207.7-58.7 37.3-22.9 70.3-51.5 98.1-85 27.1-32.7 48.7-69.5 64.2-109.1 15.5-39.7 24.4-81.3 26.6-123.8 2.4-43.6-2.5-87-14.5-129zm-60.5 181.1c-8.3 37-22.8 72-43 104-19.7 31.1-44.3 58.6-73.1 81.7-28.8 23.1-61 41-95.7 53.4-35.6 12.7-72.9 19.1-110.9 19.1-82.6 0-161.7-30.6-222.8-86.2l-34.1-35.8c-23.9-29.3-42.4-62.2-55.1-97.7-12.4-34.7-18.8-71-19.2-107.9-.4-36.9 5.4-73.3 17.1-108.2 12-35.8 30-69.2 53.4-99.1 31.7-40.4 71.1-72 117.2-94.1 44.5-21.3 94-32.6 143.4-32.6 49.3 0 97 10.8 141.8 32 34.3 16.3 65.3 38.1 92 64.8 26.1 26 47.5 56 63.6 89.2 16.2 33.2 26.6 68.5 31 105.1 4.6 37.5 2.7 75.3-5.6 112.3z" fill="currentColor"></path></svg></button><button type="button" class="wl-action" title="表情包"><svg width="24" height="24" fill="currentcolor" viewBox="0 0 24 24"><path style="transform: translateY(0.5px)" d="M18.968 10.5H15.968V11.484H17.984V12.984H15.968V15H14.468V9H18.968V10.5V10.5ZM8.984 9C9.26533 9 9.49967 9.09367 9.687 9.281C9.87433 9.46833 9.968 9.70267 9.968 9.984V10.5H6.499V13.5H8.468V12H9.968V14.016C9.968 14.2973 9.87433 14.5317 9.687 14.719C9.49967 14.9063 9.26533 15 8.984 15H5.984C5.70267 15 5.46833 14.9063 5.281 14.719C5.09367 14.5317 5 14.2973 5 14.016V9.985C5 9.70367 5.09367 9.46933 5.281 9.282C5.46833 9.09467 5.70267 9.001 5.984 9.001H8.984V9ZM11.468 9H12.968V15H11.468V9V9Z"></path><path d="M18.5 3H5.75C3.6875 3 2 4.6875 2 6.75V18C2 20.0625 3.6875 21.75 5.75 21.75H18.5C20.5625 21.75 22.25 20.0625 22.25 18V6.75C22.25 4.6875 20.5625 3 18.5 3ZM20.75 18C20.75 19.2375 19.7375 20.25 18.5 20.25H5.75C4.5125 20.25 3.5 19.2375 3.5 18V6.75C3.5 5.5125 4.5125 4.5 5.75 4.5H18.5C19.7375 4.5 20.75 5.5125 20.75 6.75V18Z"></path></svg></button><input id="wl-image-upload" class="upload" type="file" accept=".png,.jpg,.jpeg,.webp,.bmp,.gif"><label for="wl-image-upload" class="wl-action" title="上传图片"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M784 112H240c-88 0-160 72-160 160v480c0 88 72 160 160 160h544c88 0 160-72 160-160V272c0-88-72-160-160-160zm96 640c0 52.8-43.2 96-96 96H240c-52.8 0-96-43.2-96-96V272c0-52.8 43.2-96 96-96h544c52.8 0 96 43.2 96 96v480z" fill="currentColor"></path><path d="M352 480c52.8 0 96-43.2 96-96s-43.2-96-96-96-96 43.2-96 96 43.2 96 96 96zm0-128c17.6 0 32 14.4 32 32s-14.4 32-32 32-32-14.4-32-32 14.4-32 32-32zm462.4 379.2-3.2-3.2-177.6-177.6c-25.6-25.6-65.6-25.6-91.2 0l-80 80-36.8-36.8c-25.6-25.6-65.6-25.6-91.2 0L200 728c-4.8 6.4-8 14.4-8 24 0 17.6 14.4 32 32 32 9.6 0 16-3.2 22.4-9.6L380.8 640l134.4 134.4c6.4 6.4 14.4 9.6 24 9.6 17.6 0 32-14.4 32-32 0-9.6-4.8-17.6-9.6-24l-52.8-52.8 80-80L769.6 776c6.4 4.8 12.8 8 20.8 8 17.6 0 32-14.4 32-32 0-8-3.2-16-8-20.8z" fill="currentColor"></path></svg></label><button type="button" class="wl-action" title="预览"><svg viewBox="0 0 1024 1024" width="24" height="24"><path d="M710.816 654.301c70.323-96.639 61.084-230.578-23.705-314.843-46.098-46.098-107.183-71.109-172.28-71.109-65.008 0-126.092 25.444-172.28 71.109-45.227 46.098-70.756 107.183-70.756 172.106 0 64.923 25.444 126.007 71.194 172.106 46.099 46.098 107.184 71.109 172.28 71.109 51.414 0 100.648-16.212 142.824-47.404l126.53 126.006c7.058 7.06 16.297 10.979 26.406 10.979 10.105 0 19.343-3.919 26.402-10.979 14.467-14.467 14.467-38.172 0-52.723L710.816 654.301zm-315.107-23.265c-65.88-65.88-65.88-172.54 0-238.42 32.069-32.07 74.245-49.149 119.471-49.149 45.227 0 87.407 17.603 119.472 49.149 65.88 65.879 65.88 172.539 0 238.42-63.612 63.178-175.242 63.178-238.943 0zm0 0" fill="currentColor"></path><path d="M703.319 121.603H321.03c-109.8 0-199.469 89.146-199.469 199.38v382.034c0 109.796 89.236 199.38 199.469 199.38h207.397c20.653 0 37.384-16.645 37.384-37.299 0-20.649-16.731-37.296-37.384-37.296H321.03c-68.582 0-124.352-55.77-124.352-124.267V321.421c0-68.496 55.77-124.267 124.352-124.267h382.289c68.582 0 124.352 55.771 124.352 124.267V524.72c0 20.654 16.736 37.299 37.385 37.299 20.654 0 37.384-16.645 37.384-37.299V320.549c-.085-109.8-89.321-198.946-199.121-198.946zm0 0" fill="currentColor"></path></svg></button></div><div class="wl-info"><div class="wl-captcha-container"></div><div class="wl-text-number">0 <!--v-if-->  字</div><button type="button" class="wl-btn">登录</button><button type="submit" class="primary wl-btn" title="Cmd|Ctrl + Enter"><!--[-->提交<!--]--></button></div><div class="wl-gif-popup"><input type="text" placeholder="搜索表情包"><!--v-if--><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div></div><div class="wl-emoji-popup"><!--[--><!--]--><!--v-if--></div></div></div><!--v-if--></div><div class="wl-meta-head"><div class="wl-count"><!--v-if--> 评论</div><ul class="wl-sort"><!--[--><li class="active">按正序</li><li class="">按倒序</li><li class="">按热度</li><!--]--></ul></div><div class="wl-cards"><!--[--><!--]--></div><!--[--><div class="wl-loading"><svg width="30" height="30" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid"><circle cx="50" cy="50" fill="none" stroke="currentColor" strokeWidth="4" r="40" stroke-dasharray="85 30"><animateTransform attributeName="transform" type="rotate" repeatCount="indefinite" dur="1s" values="0 50 50;360 50 50" keyTimes="0;1"></animateTransform></circle></svg></div><!--]--><div class="wl-power"> Powered by <a href="https://github.com/walinejs/waline" target="_blank" rel="noopener noreferrer"> Waline </a> v2.15.8</div></div></div><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper"><div class="vp-footer">{{setupRunningTimeFooter}}</div><div class="vp-copyright">Copyright © 2025 L.H.X</div></footer></div><!--]--><!--]--><!----><!----><!----><!--]--></div>
    <script type="module" src="/space/assets/app-8962bb0b.js" defer></script>
  </body>
</html>
